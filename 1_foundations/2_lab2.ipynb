{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Second Lab - Week 1, Day 3\n",
    "\n",
    "Today we will work with lots of models! This is a way to get comfortable with APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Important point - please read</h2>\n",
    "            <span style=\"color:#ff7800;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations.<br/><br/>If you have time, I'd love it if you submit a PR for changes in the community_contributions folder - instructions in the resources. Also, if you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports - ask ChatGPT to explain any package that you don't know\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always remember to do this!\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key not set (and this is optional)\n",
      "Google API Key exists and begins AI\n",
      "DeepSeek API Key not set (and this is optional)\n",
      "Groq API Key not set (and this is optional)\n"
     ]
    }
   ],
   "source": [
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Answer only with the question, no explanation.'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How do you balance the ethical implications of artificial intelligence deployment in society with the potential benefits that such technologies can offer, particularly in areas susceptible to bias and inequity?\n"
     ]
    }
   ],
   "source": [
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Balancing the ethical implications of artificial intelligence (AI) deployment in society with its potential benefits involves a multifaceted approach that considers ethical governance, stakeholder engagement, and the development of robust AI technologies. Here are some strategies to achieve this balance:\n",
       "\n",
       "1. **Establish Ethical Guidelines and Frameworks**: Create clear ethical guidelines that govern the development and use of AI. These frameworks should prioritize fairness, accountability, transparency, and respect for human rights. Institutions and organizations can refer to established guidelines, such as those from the IEEE, EU, or various human rights organizations.\n",
       "\n",
       "2. **Engage Stakeholders**: Involve a diverse range of stakeholders in the AI development process, including marginalized communities potentially affected by bias and inequity. Their input can help identify risks and ensure that AI solutions address real-world challenges effectively and ethically.\n",
       "\n",
       "3. **Bias Mitigation Strategies**: Implement rigorous bias detection and mitigation strategies in AI systems. This includes diverse data collection practices, algorithmic transparency, and continuous monitoring for bias and inequity in AI outputs. Data should be representative of the populations it affects, and efforts should be made to include voices from underrepresented communities in data curation processes.\n",
       "\n",
       "4. **Interdisciplinary Research**: Promote interdisciplinary collaboration between AI technologists, sociologists, ethicists, and domain experts to better understand the societal impacts of AI. This research can inform the development of more inclusive and equitable AI systems.\n",
       "\n",
       "5. **Regulation and Accountability**: Develop regulatory frameworks that ensure accountability for AI systems. This could involve establishing regulatory bodies to oversee AI deployment and enforce compliance with ethical standards. Organizations may also adopt internal accountability measures to assess the impact of their AI systems regularly.\n",
       "\n",
       "6. **Education and Awareness**: Educate stakeholders, including developers, policymakers, and the general public, about the ethical implications of AI. Awareness can foster a culture of responsibility and critical thinking around the use of AI technologies.\n",
       "\n",
       "7. **Iterative Development and Feedback Loops**: Embrace an iterative approach to AI development. This involves regularly seeking feedback and making adjustments based on real-world impacts. Pilot programs and phased rollouts can help identify issues before widespread implementation.\n",
       "\n",
       "8. **Emphasize Human-Centric Design**: Design AI systems with a human-centric approach that prioritizes user needs and ethics. This involves focusing on user experience, societal impacts, and the potential for reinforcing equitable practices through technology.\n",
       "\n",
       "9. **Leverage AI for Good**: Actively pursue applications of AI that aim to address societal challenges, such as healthcare disparities, climate change, and educational access. Highlighting these \"AI for Good\" initiatives can demonstrate the positive potential of AI technology when deployed thoughtfully.\n",
       "\n",
       "10. **Transparency and Informed Consent**: Ensure transparency in how AI systems operate, particularly those that affect people's lives. Companies and institutions should provide clear information regarding how AI systems make decisions and implement informed consent processes, where appropriate.\n",
       "\n",
       "Ultimately, navigating the ethical landscape of AI requires ongoing dialogue, proactive measures, and a commitment to leveraging technology to uplift rather than undermine societal equity and justice. By applying these strategies, we can harness the benefits of AI while mitigating the risks associated with bias and inequity."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The API we know well\n",
    "\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "response = openai.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "\"Could not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mclaude-3-7-sonnet-latest\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m claude = Anthropic()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m response = \u001b[43mclaude\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m answer = response.content[\u001b[32m0\u001b[39m].text\n\u001b[32m      9\u001b[39m display(Markdown(answer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/courses/agentic_ai/agents/.venv/lib/python3.12/site-packages/anthropic/_utils/_utils.py:283\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    281\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/courses/agentic_ai/agents/.venv/lib/python3.12/site-packages/anthropic/resources/messages/messages.py:978\u001b[39m, in \u001b[36mMessages.create\u001b[39m\u001b[34m(self, max_tokens, messages, model, metadata, service_tier, stop_sequences, stream, system, temperature, thinking, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    971\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m DEPRECATED_MODELS:\n\u001b[32m    972\u001b[39m     warnings.warn(\n\u001b[32m    973\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is deprecated and will reach end-of-life on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDEPRECATED_MODELS[model]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPlease migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    974\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m    975\u001b[39m         stacklevel=\u001b[32m3\u001b[39m,\n\u001b[32m    976\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m978\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/v1/messages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop_sequences\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    989\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    990\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    991\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthinking\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mthinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    992\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    993\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    994\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_k\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    995\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    996\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessageCreateParamsStreaming\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessageCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mRawMessageStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/courses/agentic_ai/agents/.venv/lib/python3.12/site-packages/anthropic/_base_client.py:1293\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1279\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1280\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1281\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1288\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1289\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1290\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1291\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1292\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/courses/agentic_ai/agents/.venv/lib/python3.12/site-packages/anthropic/_base_client.py:1009\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1006\u001b[39m options = \u001b[38;5;28mself\u001b[39m._prepare_options(options)\n\u001b[32m   1008\u001b[39m remaining_retries = max_retries - retries_taken\n\u001b[32m-> \u001b[39m\u001b[32m1009\u001b[39m request = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[38;5;28mself\u001b[39m._prepare_request(request)\n\u001b[32m   1012\u001b[39m kwargs: HttpxSendArgs = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/courses/agentic_ai/agents/.venv/lib/python3.12/site-packages/anthropic/_base_client.py:505\u001b[39m, in \u001b[36mBaseClient._build_request\u001b[39m\u001b[34m(self, options, retries_taken)\u001b[39m\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    503\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected JSON data type, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(json_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, cannot merge with `extra_body`\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m headers = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    506\u001b[39m params = _merge_mappings(\u001b[38;5;28mself\u001b[39m.default_query, options.params)\n\u001b[32m    507\u001b[39m content_type = headers.get(\u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/courses/agentic_ai/agents/.venv/lib/python3.12/site-packages/anthropic/_base_client.py:446\u001b[39m, in \u001b[36mBaseClient._build_headers\u001b[39m\u001b[34m(self, options, retries_taken)\u001b[39m\n\u001b[32m    436\u001b[39m custom_headers = options.headers \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m    437\u001b[39m headers_dict = _merge_mappings(\n\u001b[32m    438\u001b[39m     {\n\u001b[32m    439\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mx-stainless-timeout\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(options.timeout.read)\n\u001b[32m   (...)\u001b[39m\u001b[32m    444\u001b[39m     custom_headers,\n\u001b[32m    445\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m446\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheaders_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_headers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    448\u001b[39m \u001b[38;5;66;03m# headers are case-insensitive while dictionaries are not.\u001b[39;00m\n\u001b[32m    449\u001b[39m headers = httpx.Headers(headers_dict)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/courses/agentic_ai/agents/.venv/lib/python3.12/site-packages/anthropic/_client.py:196\u001b[39m, in \u001b[36mAnthropic._validate_headers\u001b[39m\u001b[34m(self, headers, custom_headers)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(custom_headers.get(\u001b[33m\"\u001b[39m\u001b[33mAuthorization\u001b[39m\u001b[33m\"\u001b[39m), Omit):\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    197\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    198\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: \"Could not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\""
     ]
    }
   ],
   "source": [
    "# Anthropic has a slightly different API, and Max Tokens is required\n",
    "\n",
    "model_name = \"claude-3-7-sonnet-latest\"\n",
    "\n",
    "claude = Anthropic()\n",
    "response = claude.messages.create(model=model_name, messages=messages, max_tokens=1000)\n",
    "answer = response.content[0].text\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Balancing the ethical implications of AI deployment with its potential benefits, especially in areas susceptible to bias and inequity, is one of the most critical challenges of our time. It's not a static problem with a single solution, but a continuous, iterative process that requires a multi-faceted approach.\n",
       "\n",
       "Here's how to approach this balance:\n",
       "\n",
       "### Foundational Principles\n",
       "\n",
       "1.  **Human-Centric Design:** Always prioritize human well-being, autonomy, and rights. AI should augment, not diminish, human capabilities and dignity.\n",
       "2.  **Proactive Risk Assessment & Mitigation:** Don't wait for problems to arise. Identify potential harms (bias, privacy breaches, job displacement, misuse) at the design stage and build safeguards in.\n",
       "3.  **Contextual Awareness:** Recognize that the ethical implications and potential benefits vary greatly depending on the specific application area (e.g., healthcare, criminal justice, finance, education, social welfare). A \"one-size-fits-all\" approach won't work.\n",
       "4.  **Responsible Innovation:** Embrace innovation, but with a strong ethical compass. This means fostering a culture within organizations that values ethical considerations as much as technical prowess and market success.\n",
       "\n",
       "### Practical Strategies for Balancing\n",
       "\n",
       "1.  **Prioritize Fairness and Bias Mitigation (Especially in Sensitive Areas):**\n",
       "    *   **Diverse Data Sourcing & Curation:** Actively seek diverse and representative datasets. Understand their provenance, limitations, and potential biases. Avoid reliance on historical data that reflects past discrimination.\n",
       "    *   **Bias Detection & Mitigation Techniques:** Employ technical methods (e.g., fairness metrics, adversarial debiasing, re-weighting) throughout the AI lifecycle – from data collection and model training to deployment and monitoring.\n",
       "    *   **Fairness Auditing:** Regularly audit algorithms for disparate impact on different demographic groups, even if the model achieves high overall accuracy. Focus on sensitive attributes like race, gender, socioeconomic status, and disability.\n",
       "    *   **Intersectional Analysis:** Recognize that bias often compounds for individuals belonging to multiple marginalized groups.\n",
       "\n",
       "2.  **Ensure Transparency and Explainability (XAI):**\n",
       "    *   **Openness about AI Capabilities and Limitations:** Clearly communicate what an AI system can and cannot do, and under what conditions it might err.\n",
       "    *   **Explainable AI (XAI):** Develop and deploy models that can explain their decisions in an understandable way, particularly when those decisions have significant impacts (e.g., loan denial, medical diagnosis, hiring recommendations). This helps identify and challenge discriminatory outcomes.\n",
       "    *   **Process Transparency:** Be clear about the data used, the algorithms applied, and the decision-making processes involved.\n",
       "\n",
       "3.  **Implement Robust Governance and Accountability:**\n",
       "    *   **Ethical Review Boards/Committees:** Establish independent bodies within organizations or externally to review AI projects for ethical implications before and during deployment.\n",
       "    *   **Clear Lines of Responsibility:** Define who is accountable for AI failures, biases, or harms. This includes developers, deployers, and operators.\n",
       "    *   **Impact Assessments:** Conduct thorough AI Ethics Impact Assessments (AI EIAs) before deployment, similar to environmental impact assessments.\n",
       "    *   **Regulatory Frameworks:** Advocate for and comply with smart, adaptive regulations that provide guardrails without stifling innovation (e.g., GDPR, EU AI Act).\n",
       "\n",
       "4.  **Foster Human Oversight and Intervention:**\n",
       "    *   **Human-in-the-Loop (HITL) / Human-on-the-Loop (HOTL):** Design systems where human review, intervention, and override are possible, especially for critical decisions or high-risk applications. AI should be a tool to assist, not replace, human judgment.\n",
       "    *   **Empower Human Operators:** Provide humans with the necessary training, tools, and authority to understand, correct, and even halt AI systems when necessary.\n",
       "\n",
       "5.  **Engage Diverse Stakeholders:**\n",
       "    *   **Inclusive Design & Co-Creation:** Involve affected communities, social scientists, ethicists, legal experts, and civil society organizations in the design, development, and evaluation phases. Those most susceptible to bias and inequity should have a voice in shaping the technology that impacts them.\n",
       "    *   **Feedback Mechanisms:** Establish clear channels for users and the public to provide feedback, report issues, and seek redress for adverse AI outcomes.\n",
       "\n",
       "6.  **Conduct Continuous Monitoring and Iteration:**\n",
       "    *   **Post-Deployment Auditing:** AI models can \"drift\" or develop new biases over time due to changes in data or environment. Continuous monitoring and regular re-auditing are essential.\n",
       "    *   **Adaptive Learning:** Systems should be designed to learn from errors, feedback, and emerging societal impacts.\n",
       "    *   **Sunset Clauses:** For high-risk AI, consider review periods or \"sunset clauses\" where systems are automatically re-evaluated for continued ethical deployment.\n",
       "\n",
       "7.  **Invest in Education and Literacy:**\n",
       "    *   **Ethical AI Training:** Provide comprehensive ethical AI training for developers, data scientists, project managers, and leaders.\n",
       "    *   **Public AI Literacy:** Educate the public about how AI works, its benefits, its risks, and their rights concerning AI systems. This empowers individuals to engage critically with AI.\n",
       "\n",
       "By integrating these strategies, society can work towards leveraging the immense potential of AI – for example, in predictive healthcare, personalized education, efficient resource allocation, or even identifying systemic inequities – while actively mitigating its risks and ensuring it serves all members of society equitably and ethically. It's about designing AI not just for efficiency or profit, but for societal good and justice."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.5-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com/v1\")\n",
    "model_name = \"deepseek-chat\"\n",
    "\n",
    "response = deepseek.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "model_name = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "response = groq.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the next cell, we will use Ollama\n",
    "\n",
    "Ollama runs a local web service that gives an OpenAI compatible endpoint,  \n",
    "and runs models locally using high performance C++ code.\n",
    "\n",
    "If you don't have Ollama, install it here by visiting https://ollama.com then pressing Download and following the instructions.\n",
    "\n",
    "After it's installed, you should be able to visit here: http://localhost:11434 and see the message \"Ollama is running\"\n",
    "\n",
    "You might need to restart Cursor (and maybe reboot). Then open a Terminal (control+\\`) and run `ollama serve`\n",
    "\n",
    "Useful Ollama commands (run these in the terminal, or with an exclamation mark in this notebook):\n",
    "\n",
    "`ollama pull <model_name>` downloads a model locally  \n",
    "`ollama ls` lists all the models you've downloaded  \n",
    "`ollama rm <model_name>` deletes the specified model from your downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Super important - ignore me at your peril!</h2>\n",
    "            <span style=\"color:#ff7800;\">The model called <b>llama3.3</b> is FAR too large for home computers - it's not intended for personal computing and will consume all your resources! Stick with the nicely sized <b>llama3.2</b> or <b>llama3.2:1b</b> and if you want larger, try llama3.1 or smaller variants of Qwen, Gemma, Phi or DeepSeek. See the <A href=\"https://ollama.com/models\">the Ollama models page</a> for a full list of models and sizes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: ollama: command not found\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Balancing the Ethical Implications of Artificial Intelligence Deployment\n",
       "=================================================================\n",
       "\n",
       "Artificial intelligence (AI) has transformed numerous aspects of modern life, from healthcare and education to finance and transportation. However, as AI becomes increasingly pervasive, concerns regarding its ethical implications have grown. One of the primary challenges is balancing the benefits that AI can offer with the potential risks and negative consequences it may pose.\n",
       "\n",
       "Understanding Artificial Intelligence\n",
       "-----------------------------------\n",
       "\n",
       "Before delving into the balance between ethical implications and benefits, it's essential to understand what artificial intelligence entails. AI refers to systems that mimic human cognition through machine learning algorithms, which enable these systems to learn from data and make decisions based on that data. The effectiveness of AI in various tasks is undeniable, ranging from personalized recommendations and predictive maintenance to medical diagnosis and autonomous vehicles.\n",
       "\n",
       "Ethical Implications of Artificial Intelligence\n",
       "------------------------------------------------\n",
       "\n",
       "The deployment of artificial intelligence in society comes with significant ethical implications:\n",
       "\n",
       "### Bias and Discrimination\n",
       "\n",
       "1. **Data Quality**: If the training data for AI models contains biases, these models may perpetuate or even amplify existing social inequities.\n",
       "2. **Lack of Diversity**: In fields like healthcare, AI-driven systems might perform differently across various demographics due to disparities in data representation.\n",
       "\n",
       "### Privacy Concerns\n",
       "\n",
       "AI systems often rely on vast amounts of personal data to operate effectively, raising questions about data privacy and security:\n",
       "\n",
       "1. **Data Collection**: The process of gathering and processing personal information can be intrusive and potentially violate individual rights.\n",
       "2. **Data Protection**: Ensuring that collected data is secured against unauthorized access or breaches is a critical challenge.\n",
       "\n",
       "### Job Displacement\n",
       "\n",
       "The automation facilitated by AI has significant implications for the labor market, with concerns about job displacement:\n",
       "\n",
       "1. **Automated Workflows**: While AI can enhance productivity and efficiency, it also poses risks of replacing human workers in various sectors.\n",
       "2. **Skill Gaps**: The increasing demand for skills related to AI development and deployment may exacerbate existing skill gaps and inequities.\n",
       "\n",
       "Balancing Ethical Implications with Potential Benefits\n",
       "--------------------------------------------------------\n",
       "\n",
       "Given the complex landscape of ethical considerations surrounding artificial intelligence, how can we balance these concerns with the potential benefits that such technologies offer?\n",
       "\n",
       "### Education and Awareness\n",
       "\n",
       "1. **Promoting Literacy**: Educating both developers and the general public about AI's capabilities and limitations is crucial for fostering a more informed dialogue.\n",
       "2. **Open Communication**: Encouraging transparent discussions about the implications of AI can help mitigate fears and misconceptions.\n",
       "\n",
       "### Diversity, Equity, and Inclusion\n",
       "\n",
       "Fostering diversity within AI development teams can lead to more inclusive solutions:\n",
       "\n",
       "1. **Diverse Development Teams**: Ensuring that development teams reflect a broad range of backgrounds and perspectives can contribute to less biased AI systems.\n",
       "2. **Inclusive Design Principles**: Incorporating principles of equity and inclusion into the design of AI-driven products and services is essential for mitigating the risks of exacerbating existing social inequities.\n",
       "\n",
       "### Regulatory Frameworks\n",
       "\n",
       "Establishing and adhering to regulatory standards can provide a structured approach to managing the ethical implications of AI:\n",
       "\n",
       "1. **Compliance with Regulations**: Developing and enforcing regulations that address the ethical use of AI can help mitigate potential harms.\n",
       "2. **Standards for AI Development**: Establishing clear guidelines for AI development, including considerations for bias mitigation and transparency, is vital.\n",
       "\n",
       "### Continuous Monitoring and Evaluation\n",
       "\n",
       "Regularly assessing the performance and impact of AI systems is critical for ensuring they operate ethically:\n",
       "\n",
       "1. **Ongoing Assessment**: Continuous evaluation of AI-driven solutions can help identify areas where ethical concerns may arise.\n",
       "2. **Adaptive Measures**: Implementing measures to address emerging issues or unintended consequences requires flexibility and a commitment to ongoing improvement.\n",
       "\n",
       "By adopting a multifaceted approach that encompasses education, diversity, regulatory frameworks, and continuous monitoring, we can work towards balancing the potential benefits of artificial intelligence with its ethical implications, fostering a more equitable and just society in the process."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "model_name = \"llama3.3:70b-instruct-q4_0\"\n",
    "\n",
    "response = ollama.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt-4o-mini', 'gemini-2.5-flash']\n",
      "[\"Evaluating the ethical implications of using artificial intelligence (AI) in decision-making processes requires a balanced consideration of both its potential benefits and risks. Here’s a detailed analysis along with a proposed framework to ensure accountability and transparency.\\n\\n### Ethical Implications\\n\\n#### Potential Benefits:\\n1. **Efficiency and Scalability**: AI can process vast amounts of data faster than humans, improving decision-making speed and efficiency in various domains such as healthcare, finance, and logistics.\\n2. **Data-Driven Insights**: AI can uncover patterns and insights from data that might not be visible through traditional analytical methods, enhancing the quality of decisions.\\n3. **Reduction of Human Bias**: If designed correctly, AI can help alleviate certain cognitive biases present in human decision-makers, promoting more objective outcomes.\\n\\n#### Potential Risks:\\n1. **Bias and Discrimination**: AI systems can inadvertently perpetuate or amplify biases present in training data, leading to discriminatory outcomes in critical areas such as hiring, law enforcement, and credit scoring.\\n2. **Lack of Accountability**: Decisions made by AI can be opaque, making it difficult to attribute responsibility when things go wrong. This can undermine trust in institutions that utilize AI.\\n3. **Privacy Concerns**: The collection and analysis of personal data can lead to violations of privacy rights, especially if individuals are not informed or consent is not obtained.\\n4. **Autonomy and Control**: Over-reliance on AI for decision-making can diminish human agency, as people may become passive recipients of decisions rather than active participants.\\n\\n### Framework for Accountability and Transparency\\n\\nTo address the ethical implications of AI in decision-making, a structured framework is essential. This framework should include the following components:\\n\\n1. **Ethical Guidelines and Standards**:\\n   - Establish baseline ethical principles (e.g., fairness, accountability, transparency, privacy, and human dignity) that guide AI development and deployment.\\n   - Use established frameworks such as the IEEE's Ethically Aligned Design or the EU’s Ethics Guidelines for Trustworthy AI.\\n\\n2. **Transparency Mechanisms**:\\n   - Promote explainable AI (XAI) techniques that enable users and stakeholders to understand AI decision-making processes and outcomes.\\n   - Ensure public access to documentation regarding AI systems, including their design, data sources, and algorithms used.\\n\\n3. **Bias Audits and Fairness Measures**:\\n   - Implement regular audits of AI systems to identify and mitigate biases, incorporating fairness metrics that assess the impact of AI decisions across different demographic groups.\\n   - Engage diverse stakeholders in the development process to ensure that the perspectives and experiences of all affected groups are considered.\\n\\n4. **Accountability Structures**:\\n   - Define clear lines of accountability for AI decisions, ensuring that human overseers are responsible for outcomes.\\n   - Establish incident reporting mechanisms to track and address failures or biases in AI systems promptly.\\n\\n5. **Stakeholder Engagement and Public Discourse**:\\n   - Involve stakeholders—including community representatives, ethicists, and technologists—in the design and evaluation of AI systems to address societal concerns collaboratively.\\n   - Foster public discourse around AI use, its implications, and community values to ensure broader societal input in decision-making processes.\\n\\n6. **Regulatory Oversight**:\\n   - Advocate for appropriate regulations that govern AI use in decision-making, which could include standards for data protection and algorithmic accountability.\\n   - Encourage adaptability in regulations to keep pace with rapidly evolving technology.\\n\\n7. **Continuous Monitoring and Feedback**:\\n   - Establish a system for ongoing monitoring of AI impacts, including stakeholder feedback mechanisms, to assess the effectiveness of implemented ethical guidelines.\\n\\nBy adopting this framework, organizations can work towards ensuring that AI systems are used ethically, responsibly, and transparently while harnessing their benefits to enhance decision-making. Ultimately, maintaining a human-centric approach is vital to fostering trust and maximizing the positive impact of AI in society.\", 'The use of artificial intelligence in decision-making processes presents a complex ethical landscape, balancing immense potential for good with significant risks. Evaluating these implications requires a nuanced perspective, considering both the benefits AI can bring and the critical challenges it poses to human values, rights, and societal structures.\\n\\n## Ethical Implications: Benefits and Risks\\n\\n### Potential Benefits:\\n\\n1.  **Enhanced Efficiency and Speed:** AI can process vast amounts of data and make decisions far more quickly than humans, leading to faster service delivery, more responsive systems, and optimized operations in areas like logistics, finance, and emergency response.\\n2.  **Improved Accuracy and Consistency:** For well-defined tasks, AI can reduce human error, fatigue, and emotional bias, leading to more consistent and often more accurate outcomes. This is particularly valuable in fields like medical diagnosis, quality control, and fraud detection.\\n3.  **Identification of Hidden Patterns:** AI\\'s ability to analyze complex datasets can uncover correlations and insights that humans might miss, leading to innovative solutions, better predictive models (e.g., disease outbreaks, market trends), and more informed strategic decisions.\\n4.  **Scalability:** AI models can be deployed across a wide range of applications and scale up to meet demand without the limitations of human resources, enabling the delivery of services to a larger population.\\n5.  **Reduced Human Bias (in theory):** While AI can amplify existing biases, it also offers the potential, if designed and trained carefully, to mitigate certain forms of human bias (e.g., favoritism, prejudice based on personal feelings) by applying objective criteria.\\n6.  **Augmentation of Human Capabilities:** Rather than replacing humans, AI can serve as a powerful tool, augmenting human decision-makers with data-driven insights, allowing them to focus on more complex, creative, or empathetic aspects of a problem.\\n\\n### Potential Risks and Ethical Concerns:\\n\\n1.  **Algorithmic Bias and Discrimination:** AI systems learn from data, and if the data reflects historical or societal biases, the AI will learn and perpetuate these biases, leading to discriminatory outcomes. This is a critical concern in areas like criminal justice (sentencing, policing), hiring, loan applications, and healthcare.\\n    *   *Ethical Implication:* Undermines fairness, equality, and justice; can exacerbate societal inequalities.\\n2.  **Lack of Transparency and Explainability (\"Black Box\" Problem):** Many advanced AI models (especially deep learning) are \"black boxes,\" making it difficult or impossible for humans to understand how they arrive at a particular decision. This makes auditing, identifying errors, and challenging outcomes incredibly difficult.\\n    *   *Ethical Implication:* Erodes trust, hinders accountability, violates the right to explanation, and challenges due process.\\n3.  **Accountability Gap:** When an AI system makes a flawed or harmful decision, it\\'s often unclear who is responsible: the developer, the deployer, the data provider, the user, or the AI itself? This \"liability vacuum\" can impede redress for harm.\\n    *   *Ethical Implication:* Undermines justice and victim compensation; can lead to a diffusion of responsibility.\\n4.  **Autonomy and Loss of Human Control/Oversight:** Over-reliance on AI can lead to a gradual ceding of human judgment and control, especially in critical domains like autonomous weapons systems or high-stakes financial trading. Humans may become complacent or unable to intervene effectively.\\n    *   *Ethical Implication:* Risks dehumanization, loss of moral agency, and potentially catastrophic unintended consequences.\\n5.  **Privacy Violations and Data Security:** AI systems often require vast amounts of personal data for training and operation, raising concerns about data collection, storage, use, and potential breaches.\\n    *   *Ethical Implication:* Infringes on individual privacy rights and can lead to surveillance societies or identity theft.\\n6.  **Job Displacement and Economic Inequality:** As AI automates more tasks, there\\'s a risk of significant job displacement across various sectors, potentially exacerbating economic inequality and social unrest if not managed properly.\\n    *   *Ethical Implication:* Raises questions of distributive justice and societal well-being.\\n7.  **Reinforcement of Power Structures:** Those who control and develop AI have significant power to shape societal norms and outcomes. This can further entrench existing power structures or create new ones, potentially leading to technological authoritarianism.\\n    *   *Ethical Implication:* Threatens democratic principles and human flourishing.\\n8.  **Ethical Dilemmas and Moral Agency:** In situations with no clear right or wrong answer (e.g., self-driving cars in unavoidable accident scenarios), AI must be programmed with explicit or implicit ethical frameworks, raising profound questions about who decides these moral rules and how.\\n    *   *Ethical Implication:* Challenges fundamental human moral reasoning and societal values.\\n\\n## Proposed Framework for Accountability and Transparency\\n\\nTo navigate these challenges, a multi-faceted framework is necessary, encompassing legal, technical, organizational, and societal dimensions.\\n\\n### Guiding Principles:\\n\\n1.  **Human-Centricity:** AI systems should augment human capabilities, respect human dignity, and ultimately serve human well-being. Human oversight and intervention should always be possible, especially in critical decisions.\\n2.  **Fairness and Non-Discrimination:** AI systems must be designed, developed, and deployed to avoid unfair bias and discrimination, ensuring equitable treatment and opportunities for all.\\n3.  **Transparency and Explainability:** The decision-making processes of AI systems should be as understandable and interpretable as possible, commensurate with the risk and impact of their decisions.\\n4.  **Accountability and Redressability:** Clear lines of responsibility must be established for AI systems, and mechanisms must exist for affected individuals to seek explanation, challenge decisions, and obtain redress for harm.\\n5.  **Robustness and Safety:** AI systems must be reliable, secure, and resilient to errors, manipulation, and cyber-attacks, ensuring they perform as intended and do not cause unintended harm.\\n6.  **Privacy and Data Governance:** Strict data protection principles must be applied throughout the AI lifecycle, respecting individual privacy rights and ensuring responsible data collection, use, and storage.\\n7.  **Beneficence and Sustainability:** AI development and deployment should contribute positively to society, aligning with ethical values and environmental sustainability goals.\\n\\n### Framework Pillars for Accountability and Transparency:\\n\\n**1. Legal and Regulatory Frameworks:**\\n\\n*   **Sector-Specific Regulations:** Develop laws tailored to high-risk AI applications (e.g., healthcare, finance, justice), mandating ethical guidelines, auditing requirements, and liability rules. (e.g., EU AI Act, which classifies AI by risk level).\\n*   **\"Right to Explanation\" and Human Review:** Legally mandate that individuals affected by AI-driven decisions have the right to understand the basis of the decision and to request human review or intervention, especially in high-stakes contexts.\\n*   **Clear Liability Regimes:** Establish legal frameworks that clearly assign accountability for harm caused by AI systems (e.g., producer liability, operator liability) to ensure victims can seek redress.\\n*   **Data Protection Laws:** Strengthen and enforce comprehensive data protection regulations (like GDPR) that govern the collection, processing, and use of data for AI training and deployment.\\n*   **Standardization and Certification:** Develop industry standards and potentially certification processes for AI systems to demonstrate compliance with ethical, safety, and performance requirements.\\n\\n**2. Technical and Methodological Solutions:**\\n\\n*   **Explainable AI (XAI) Tools:** Invest in and develop tools and techniques that make AI models more interpretable, allowing developers, auditors, and users to understand how a decision was reached. This includes techniques like LIME, SHAP, and causal inference.\\n*   **Bias Detection and Mitigation Tools:** Implement tools to proactively identify and mitigate algorithmic biases in data collection, model training, and deployment, alongside continuous monitoring for discriminatory outcomes.\\n*   **Robustness and Adversarial Testing:** Develop rigorous testing methodologies to ensure AI systems are resilient to adversarial attacks, data perturbations, and unexpected inputs, enhancing reliability and safety.\\n*   **Data Provenance and Audit Trails:** Implement mechanisms to track the origin and transformations of data used to train AI models, creating comprehensive audit trails for transparency and debugging.\\n*   **Privacy-Preserving AI:** Utilize techniques like federated learning, differential privacy, and homomorphic encryption to train AI models without directly accessing sensitive raw data.\\n*   **Algorithmic Transparency Reports:** Encourage or mandate the publication of \"nutrition labels\" or impact assessments for AI systems, detailing their purpose, data sources, performance metrics, and known limitations/risks.\\n\\n**3. Organizational and Governance Mechanisms:**\\n\\n*   **AI Ethics Boards/Committees:** Establish independent or internal AI ethics boards composed of diverse experts (technologists, ethicists, legal scholars, social scientists) to review, guide, and oversee the development and deployment of AI.\\n*   **AI Impact Assessments (AIIA):** Mandate comprehensive assessments before deploying high-risk AI systems, similar to environmental or privacy impact assessments, to identify and mitigate potential ethical, social, and economic risks.\\n*   **Ethical AI Guidelines and Codes of Conduct:** Develop and enforce internal ethical guidelines and codes of conduct for AI developers, researchers, and deployers, integrating ethical considerations into the AI lifecycle from design to decommission.\\n*   **Responsible AI Leadership and Training:** Foster a culture of responsible AI through leadership commitment, continuous ethical training for all involved personnel, and the allocation of resources for ethical AI research and implementation.\\n*   **Post-Deployment Monitoring and Auditing:** Implement continuous monitoring systems to track AI performance, identify unintended consequences, and trigger human intervention when necessary. Regular independent audits should assess compliance with ethical and performance standards.\\n*   **Whistleblower Protections:** Create safe channels and protections for individuals to report concerns about potentially harmful or unethical AI deployments.\\n\\n**4. Societal and Educational Initiatives:**\\n\\n*   **Public Education and Digital Literacy:** Promote widespread public understanding of AI\\'s capabilities, limitations, and ethical implications, empowering citizens to engage critically with AI systems.\\n*   **Multi-Stakeholder Dialogue:** Foster ongoing dialogue and collaboration among governments, industry, academia, civil society organizations, and the public to shape AI policy and best practices.\\n*   **Ethical AI Research Funding:** Prioritize and fund research specifically focused on ethical AI, including explainability, bias mitigation, fairness metrics, and value alignment.\\n*   **Citizen Participation:** Include citizen panels or participatory design approaches in the development and deployment of AI systems, especially those with significant public impact.\\n\\nBy implementing this comprehensive framework, societies can harness the transformative power of AI while proactively addressing its ethical challenges, ensuring that AI development and deployment are accountable, transparent, and ultimately serve the greater good. This requires continuous adaptation, as AI technology evolves and its societal impacts become clearer.']\n"
     ]
    }
   ],
   "source": [
    "# So where are we?\n",
    "\n",
    "print(competitors)\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Competitor: gpt-4o-mini\n",
      "\n",
      "Evaluating the ethical implications of using artificial intelligence (AI) in decision-making processes requires a balanced consideration of both its potential benefits and risks. Here’s a detailed analysis along with a proposed framework to ensure accountability and transparency.\n",
      "\n",
      "### Ethical Implications\n",
      "\n",
      "#### Potential Benefits:\n",
      "1. **Efficiency and Scalability**: AI can process vast amounts of data faster than humans, improving decision-making speed and efficiency in various domains such as healthcare, finance, and logistics.\n",
      "2. **Data-Driven Insights**: AI can uncover patterns and insights from data that might not be visible through traditional analytical methods, enhancing the quality of decisions.\n",
      "3. **Reduction of Human Bias**: If designed correctly, AI can help alleviate certain cognitive biases present in human decision-makers, promoting more objective outcomes.\n",
      "\n",
      "#### Potential Risks:\n",
      "1. **Bias and Discrimination**: AI systems can inadvertently perpetuate or amplify biases present in training data, leading to discriminatory outcomes in critical areas such as hiring, law enforcement, and credit scoring.\n",
      "2. **Lack of Accountability**: Decisions made by AI can be opaque, making it difficult to attribute responsibility when things go wrong. This can undermine trust in institutions that utilize AI.\n",
      "3. **Privacy Concerns**: The collection and analysis of personal data can lead to violations of privacy rights, especially if individuals are not informed or consent is not obtained.\n",
      "4. **Autonomy and Control**: Over-reliance on AI for decision-making can diminish human agency, as people may become passive recipients of decisions rather than active participants.\n",
      "\n",
      "### Framework for Accountability and Transparency\n",
      "\n",
      "To address the ethical implications of AI in decision-making, a structured framework is essential. This framework should include the following components:\n",
      "\n",
      "1. **Ethical Guidelines and Standards**:\n",
      "   - Establish baseline ethical principles (e.g., fairness, accountability, transparency, privacy, and human dignity) that guide AI development and deployment.\n",
      "   - Use established frameworks such as the IEEE's Ethically Aligned Design or the EU’s Ethics Guidelines for Trustworthy AI.\n",
      "\n",
      "2. **Transparency Mechanisms**:\n",
      "   - Promote explainable AI (XAI) techniques that enable users and stakeholders to understand AI decision-making processes and outcomes.\n",
      "   - Ensure public access to documentation regarding AI systems, including their design, data sources, and algorithms used.\n",
      "\n",
      "3. **Bias Audits and Fairness Measures**:\n",
      "   - Implement regular audits of AI systems to identify and mitigate biases, incorporating fairness metrics that assess the impact of AI decisions across different demographic groups.\n",
      "   - Engage diverse stakeholders in the development process to ensure that the perspectives and experiences of all affected groups are considered.\n",
      "\n",
      "4. **Accountability Structures**:\n",
      "   - Define clear lines of accountability for AI decisions, ensuring that human overseers are responsible for outcomes.\n",
      "   - Establish incident reporting mechanisms to track and address failures or biases in AI systems promptly.\n",
      "\n",
      "5. **Stakeholder Engagement and Public Discourse**:\n",
      "   - Involve stakeholders—including community representatives, ethicists, and technologists—in the design and evaluation of AI systems to address societal concerns collaboratively.\n",
      "   - Foster public discourse around AI use, its implications, and community values to ensure broader societal input in decision-making processes.\n",
      "\n",
      "6. **Regulatory Oversight**:\n",
      "   - Advocate for appropriate regulations that govern AI use in decision-making, which could include standards for data protection and algorithmic accountability.\n",
      "   - Encourage adaptability in regulations to keep pace with rapidly evolving technology.\n",
      "\n",
      "7. **Continuous Monitoring and Feedback**:\n",
      "   - Establish a system for ongoing monitoring of AI impacts, including stakeholder feedback mechanisms, to assess the effectiveness of implemented ethical guidelines.\n",
      "\n",
      "By adopting this framework, organizations can work towards ensuring that AI systems are used ethically, responsibly, and transparently while harnessing their benefits to enhance decision-making. Ultimately, maintaining a human-centric approach is vital to fostering trust and maximizing the positive impact of AI in society.\n",
      "Competitor: gemini-2.5-flash\n",
      "\n",
      "The use of artificial intelligence in decision-making processes presents a complex ethical landscape, balancing immense potential for good with significant risks. Evaluating these implications requires a nuanced perspective, considering both the benefits AI can bring and the critical challenges it poses to human values, rights, and societal structures.\n",
      "\n",
      "## Ethical Implications: Benefits and Risks\n",
      "\n",
      "### Potential Benefits:\n",
      "\n",
      "1.  **Enhanced Efficiency and Speed:** AI can process vast amounts of data and make decisions far more quickly than humans, leading to faster service delivery, more responsive systems, and optimized operations in areas like logistics, finance, and emergency response.\n",
      "2.  **Improved Accuracy and Consistency:** For well-defined tasks, AI can reduce human error, fatigue, and emotional bias, leading to more consistent and often more accurate outcomes. This is particularly valuable in fields like medical diagnosis, quality control, and fraud detection.\n",
      "3.  **Identification of Hidden Patterns:** AI's ability to analyze complex datasets can uncover correlations and insights that humans might miss, leading to innovative solutions, better predictive models (e.g., disease outbreaks, market trends), and more informed strategic decisions.\n",
      "4.  **Scalability:** AI models can be deployed across a wide range of applications and scale up to meet demand without the limitations of human resources, enabling the delivery of services to a larger population.\n",
      "5.  **Reduced Human Bias (in theory):** While AI can amplify existing biases, it also offers the potential, if designed and trained carefully, to mitigate certain forms of human bias (e.g., favoritism, prejudice based on personal feelings) by applying objective criteria.\n",
      "6.  **Augmentation of Human Capabilities:** Rather than replacing humans, AI can serve as a powerful tool, augmenting human decision-makers with data-driven insights, allowing them to focus on more complex, creative, or empathetic aspects of a problem.\n",
      "\n",
      "### Potential Risks and Ethical Concerns:\n",
      "\n",
      "1.  **Algorithmic Bias and Discrimination:** AI systems learn from data, and if the data reflects historical or societal biases, the AI will learn and perpetuate these biases, leading to discriminatory outcomes. This is a critical concern in areas like criminal justice (sentencing, policing), hiring, loan applications, and healthcare.\n",
      "    *   *Ethical Implication:* Undermines fairness, equality, and justice; can exacerbate societal inequalities.\n",
      "2.  **Lack of Transparency and Explainability (\"Black Box\" Problem):** Many advanced AI models (especially deep learning) are \"black boxes,\" making it difficult or impossible for humans to understand how they arrive at a particular decision. This makes auditing, identifying errors, and challenging outcomes incredibly difficult.\n",
      "    *   *Ethical Implication:* Erodes trust, hinders accountability, violates the right to explanation, and challenges due process.\n",
      "3.  **Accountability Gap:** When an AI system makes a flawed or harmful decision, it's often unclear who is responsible: the developer, the deployer, the data provider, the user, or the AI itself? This \"liability vacuum\" can impede redress for harm.\n",
      "    *   *Ethical Implication:* Undermines justice and victim compensation; can lead to a diffusion of responsibility.\n",
      "4.  **Autonomy and Loss of Human Control/Oversight:** Over-reliance on AI can lead to a gradual ceding of human judgment and control, especially in critical domains like autonomous weapons systems or high-stakes financial trading. Humans may become complacent or unable to intervene effectively.\n",
      "    *   *Ethical Implication:* Risks dehumanization, loss of moral agency, and potentially catastrophic unintended consequences.\n",
      "5.  **Privacy Violations and Data Security:** AI systems often require vast amounts of personal data for training and operation, raising concerns about data collection, storage, use, and potential breaches.\n",
      "    *   *Ethical Implication:* Infringes on individual privacy rights and can lead to surveillance societies or identity theft.\n",
      "6.  **Job Displacement and Economic Inequality:** As AI automates more tasks, there's a risk of significant job displacement across various sectors, potentially exacerbating economic inequality and social unrest if not managed properly.\n",
      "    *   *Ethical Implication:* Raises questions of distributive justice and societal well-being.\n",
      "7.  **Reinforcement of Power Structures:** Those who control and develop AI have significant power to shape societal norms and outcomes. This can further entrench existing power structures or create new ones, potentially leading to technological authoritarianism.\n",
      "    *   *Ethical Implication:* Threatens democratic principles and human flourishing.\n",
      "8.  **Ethical Dilemmas and Moral Agency:** In situations with no clear right or wrong answer (e.g., self-driving cars in unavoidable accident scenarios), AI must be programmed with explicit or implicit ethical frameworks, raising profound questions about who decides these moral rules and how.\n",
      "    *   *Ethical Implication:* Challenges fundamental human moral reasoning and societal values.\n",
      "\n",
      "## Proposed Framework for Accountability and Transparency\n",
      "\n",
      "To navigate these challenges, a multi-faceted framework is necessary, encompassing legal, technical, organizational, and societal dimensions.\n",
      "\n",
      "### Guiding Principles:\n",
      "\n",
      "1.  **Human-Centricity:** AI systems should augment human capabilities, respect human dignity, and ultimately serve human well-being. Human oversight and intervention should always be possible, especially in critical decisions.\n",
      "2.  **Fairness and Non-Discrimination:** AI systems must be designed, developed, and deployed to avoid unfair bias and discrimination, ensuring equitable treatment and opportunities for all.\n",
      "3.  **Transparency and Explainability:** The decision-making processes of AI systems should be as understandable and interpretable as possible, commensurate with the risk and impact of their decisions.\n",
      "4.  **Accountability and Redressability:** Clear lines of responsibility must be established for AI systems, and mechanisms must exist for affected individuals to seek explanation, challenge decisions, and obtain redress for harm.\n",
      "5.  **Robustness and Safety:** AI systems must be reliable, secure, and resilient to errors, manipulation, and cyber-attacks, ensuring they perform as intended and do not cause unintended harm.\n",
      "6.  **Privacy and Data Governance:** Strict data protection principles must be applied throughout the AI lifecycle, respecting individual privacy rights and ensuring responsible data collection, use, and storage.\n",
      "7.  **Beneficence and Sustainability:** AI development and deployment should contribute positively to society, aligning with ethical values and environmental sustainability goals.\n",
      "\n",
      "### Framework Pillars for Accountability and Transparency:\n",
      "\n",
      "**1. Legal and Regulatory Frameworks:**\n",
      "\n",
      "*   **Sector-Specific Regulations:** Develop laws tailored to high-risk AI applications (e.g., healthcare, finance, justice), mandating ethical guidelines, auditing requirements, and liability rules. (e.g., EU AI Act, which classifies AI by risk level).\n",
      "*   **\"Right to Explanation\" and Human Review:** Legally mandate that individuals affected by AI-driven decisions have the right to understand the basis of the decision and to request human review or intervention, especially in high-stakes contexts.\n",
      "*   **Clear Liability Regimes:** Establish legal frameworks that clearly assign accountability for harm caused by AI systems (e.g., producer liability, operator liability) to ensure victims can seek redress.\n",
      "*   **Data Protection Laws:** Strengthen and enforce comprehensive data protection regulations (like GDPR) that govern the collection, processing, and use of data for AI training and deployment.\n",
      "*   **Standardization and Certification:** Develop industry standards and potentially certification processes for AI systems to demonstrate compliance with ethical, safety, and performance requirements.\n",
      "\n",
      "**2. Technical and Methodological Solutions:**\n",
      "\n",
      "*   **Explainable AI (XAI) Tools:** Invest in and develop tools and techniques that make AI models more interpretable, allowing developers, auditors, and users to understand how a decision was reached. This includes techniques like LIME, SHAP, and causal inference.\n",
      "*   **Bias Detection and Mitigation Tools:** Implement tools to proactively identify and mitigate algorithmic biases in data collection, model training, and deployment, alongside continuous monitoring for discriminatory outcomes.\n",
      "*   **Robustness and Adversarial Testing:** Develop rigorous testing methodologies to ensure AI systems are resilient to adversarial attacks, data perturbations, and unexpected inputs, enhancing reliability and safety.\n",
      "*   **Data Provenance and Audit Trails:** Implement mechanisms to track the origin and transformations of data used to train AI models, creating comprehensive audit trails for transparency and debugging.\n",
      "*   **Privacy-Preserving AI:** Utilize techniques like federated learning, differential privacy, and homomorphic encryption to train AI models without directly accessing sensitive raw data.\n",
      "*   **Algorithmic Transparency Reports:** Encourage or mandate the publication of \"nutrition labels\" or impact assessments for AI systems, detailing their purpose, data sources, performance metrics, and known limitations/risks.\n",
      "\n",
      "**3. Organizational and Governance Mechanisms:**\n",
      "\n",
      "*   **AI Ethics Boards/Committees:** Establish independent or internal AI ethics boards composed of diverse experts (technologists, ethicists, legal scholars, social scientists) to review, guide, and oversee the development and deployment of AI.\n",
      "*   **AI Impact Assessments (AIIA):** Mandate comprehensive assessments before deploying high-risk AI systems, similar to environmental or privacy impact assessments, to identify and mitigate potential ethical, social, and economic risks.\n",
      "*   **Ethical AI Guidelines and Codes of Conduct:** Develop and enforce internal ethical guidelines and codes of conduct for AI developers, researchers, and deployers, integrating ethical considerations into the AI lifecycle from design to decommission.\n",
      "*   **Responsible AI Leadership and Training:** Foster a culture of responsible AI through leadership commitment, continuous ethical training for all involved personnel, and the allocation of resources for ethical AI research and implementation.\n",
      "*   **Post-Deployment Monitoring and Auditing:** Implement continuous monitoring systems to track AI performance, identify unintended consequences, and trigger human intervention when necessary. Regular independent audits should assess compliance with ethical and performance standards.\n",
      "*   **Whistleblower Protections:** Create safe channels and protections for individuals to report concerns about potentially harmful or unethical AI deployments.\n",
      "\n",
      "**4. Societal and Educational Initiatives:**\n",
      "\n",
      "*   **Public Education and Digital Literacy:** Promote widespread public understanding of AI's capabilities, limitations, and ethical implications, empowering citizens to engage critically with AI systems.\n",
      "*   **Multi-Stakeholder Dialogue:** Foster ongoing dialogue and collaboration among governments, industry, academia, civil society organizations, and the public to shape AI policy and best practices.\n",
      "*   **Ethical AI Research Funding:** Prioritize and fund research specifically focused on ethical AI, including explainability, bias mitigation, fairness metrics, and value alignment.\n",
      "*   **Citizen Participation:** Include citizen panels or participatory design approaches in the development and deployment of AI systems, especially those with significant public impact.\n",
      "\n",
      "By implementing this comprehensive framework, societies can harness the transformative power of AI while proactively addressing its ethical challenges, ensuring that AI development and deployment are accountable, transparent, and ultimately serve the greater good. This requires continuous adaptation, as AI technology evolves and its societal impacts become clearer.\n"
     ]
    }
   ],
   "source": [
    "# It's nice to know how to use \"zip\"\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    print(f\"Competitor: {competitor}\\n\\n{answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring this together - note the use of \"enumerate\"\n",
    "\n",
    "together = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    together += f\"# Response from competitor {index+1}\\n\\n\"\n",
    "    together += answer + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Response from competitor 1\n",
      "\n",
      "Evaluating the ethical implications of using artificial intelligence (AI) in decision-making processes requires a balanced consideration of both its potential benefits and risks. Here’s a detailed analysis along with a proposed framework to ensure accountability and transparency.\n",
      "\n",
      "### Ethical Implications\n",
      "\n",
      "#### Potential Benefits:\n",
      "1. **Efficiency and Scalability**: AI can process vast amounts of data faster than humans, improving decision-making speed and efficiency in various domains such as healthcare, finance, and logistics.\n",
      "2. **Data-Driven Insights**: AI can uncover patterns and insights from data that might not be visible through traditional analytical methods, enhancing the quality of decisions.\n",
      "3. **Reduction of Human Bias**: If designed correctly, AI can help alleviate certain cognitive biases present in human decision-makers, promoting more objective outcomes.\n",
      "\n",
      "#### Potential Risks:\n",
      "1. **Bias and Discrimination**: AI systems can inadvertently perpetuate or amplify biases present in training data, leading to discriminatory outcomes in critical areas such as hiring, law enforcement, and credit scoring.\n",
      "2. **Lack of Accountability**: Decisions made by AI can be opaque, making it difficult to attribute responsibility when things go wrong. This can undermine trust in institutions that utilize AI.\n",
      "3. **Privacy Concerns**: The collection and analysis of personal data can lead to violations of privacy rights, especially if individuals are not informed or consent is not obtained.\n",
      "4. **Autonomy and Control**: Over-reliance on AI for decision-making can diminish human agency, as people may become passive recipients of decisions rather than active participants.\n",
      "\n",
      "### Framework for Accountability and Transparency\n",
      "\n",
      "To address the ethical implications of AI in decision-making, a structured framework is essential. This framework should include the following components:\n",
      "\n",
      "1. **Ethical Guidelines and Standards**:\n",
      "   - Establish baseline ethical principles (e.g., fairness, accountability, transparency, privacy, and human dignity) that guide AI development and deployment.\n",
      "   - Use established frameworks such as the IEEE's Ethically Aligned Design or the EU’s Ethics Guidelines for Trustworthy AI.\n",
      "\n",
      "2. **Transparency Mechanisms**:\n",
      "   - Promote explainable AI (XAI) techniques that enable users and stakeholders to understand AI decision-making processes and outcomes.\n",
      "   - Ensure public access to documentation regarding AI systems, including their design, data sources, and algorithms used.\n",
      "\n",
      "3. **Bias Audits and Fairness Measures**:\n",
      "   - Implement regular audits of AI systems to identify and mitigate biases, incorporating fairness metrics that assess the impact of AI decisions across different demographic groups.\n",
      "   - Engage diverse stakeholders in the development process to ensure that the perspectives and experiences of all affected groups are considered.\n",
      "\n",
      "4. **Accountability Structures**:\n",
      "   - Define clear lines of accountability for AI decisions, ensuring that human overseers are responsible for outcomes.\n",
      "   - Establish incident reporting mechanisms to track and address failures or biases in AI systems promptly.\n",
      "\n",
      "5. **Stakeholder Engagement and Public Discourse**:\n",
      "   - Involve stakeholders—including community representatives, ethicists, and technologists—in the design and evaluation of AI systems to address societal concerns collaboratively.\n",
      "   - Foster public discourse around AI use, its implications, and community values to ensure broader societal input in decision-making processes.\n",
      "\n",
      "6. **Regulatory Oversight**:\n",
      "   - Advocate for appropriate regulations that govern AI use in decision-making, which could include standards for data protection and algorithmic accountability.\n",
      "   - Encourage adaptability in regulations to keep pace with rapidly evolving technology.\n",
      "\n",
      "7. **Continuous Monitoring and Feedback**:\n",
      "   - Establish a system for ongoing monitoring of AI impacts, including stakeholder feedback mechanisms, to assess the effectiveness of implemented ethical guidelines.\n",
      "\n",
      "By adopting this framework, organizations can work towards ensuring that AI systems are used ethically, responsibly, and transparently while harnessing their benefits to enhance decision-making. Ultimately, maintaining a human-centric approach is vital to fostering trust and maximizing the positive impact of AI in society.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "The use of artificial intelligence in decision-making processes presents a complex ethical landscape, balancing immense potential for good with significant risks. Evaluating these implications requires a nuanced perspective, considering both the benefits AI can bring and the critical challenges it poses to human values, rights, and societal structures.\n",
      "\n",
      "## Ethical Implications: Benefits and Risks\n",
      "\n",
      "### Potential Benefits:\n",
      "\n",
      "1.  **Enhanced Efficiency and Speed:** AI can process vast amounts of data and make decisions far more quickly than humans, leading to faster service delivery, more responsive systems, and optimized operations in areas like logistics, finance, and emergency response.\n",
      "2.  **Improved Accuracy and Consistency:** For well-defined tasks, AI can reduce human error, fatigue, and emotional bias, leading to more consistent and often more accurate outcomes. This is particularly valuable in fields like medical diagnosis, quality control, and fraud detection.\n",
      "3.  **Identification of Hidden Patterns:** AI's ability to analyze complex datasets can uncover correlations and insights that humans might miss, leading to innovative solutions, better predictive models (e.g., disease outbreaks, market trends), and more informed strategic decisions.\n",
      "4.  **Scalability:** AI models can be deployed across a wide range of applications and scale up to meet demand without the limitations of human resources, enabling the delivery of services to a larger population.\n",
      "5.  **Reduced Human Bias (in theory):** While AI can amplify existing biases, it also offers the potential, if designed and trained carefully, to mitigate certain forms of human bias (e.g., favoritism, prejudice based on personal feelings) by applying objective criteria.\n",
      "6.  **Augmentation of Human Capabilities:** Rather than replacing humans, AI can serve as a powerful tool, augmenting human decision-makers with data-driven insights, allowing them to focus on more complex, creative, or empathetic aspects of a problem.\n",
      "\n",
      "### Potential Risks and Ethical Concerns:\n",
      "\n",
      "1.  **Algorithmic Bias and Discrimination:** AI systems learn from data, and if the data reflects historical or societal biases, the AI will learn and perpetuate these biases, leading to discriminatory outcomes. This is a critical concern in areas like criminal justice (sentencing, policing), hiring, loan applications, and healthcare.\n",
      "    *   *Ethical Implication:* Undermines fairness, equality, and justice; can exacerbate societal inequalities.\n",
      "2.  **Lack of Transparency and Explainability (\"Black Box\" Problem):** Many advanced AI models (especially deep learning) are \"black boxes,\" making it difficult or impossible for humans to understand how they arrive at a particular decision. This makes auditing, identifying errors, and challenging outcomes incredibly difficult.\n",
      "    *   *Ethical Implication:* Erodes trust, hinders accountability, violates the right to explanation, and challenges due process.\n",
      "3.  **Accountability Gap:** When an AI system makes a flawed or harmful decision, it's often unclear who is responsible: the developer, the deployer, the data provider, the user, or the AI itself? This \"liability vacuum\" can impede redress for harm.\n",
      "    *   *Ethical Implication:* Undermines justice and victim compensation; can lead to a diffusion of responsibility.\n",
      "4.  **Autonomy and Loss of Human Control/Oversight:** Over-reliance on AI can lead to a gradual ceding of human judgment and control, especially in critical domains like autonomous weapons systems or high-stakes financial trading. Humans may become complacent or unable to intervene effectively.\n",
      "    *   *Ethical Implication:* Risks dehumanization, loss of moral agency, and potentially catastrophic unintended consequences.\n",
      "5.  **Privacy Violations and Data Security:** AI systems often require vast amounts of personal data for training and operation, raising concerns about data collection, storage, use, and potential breaches.\n",
      "    *   *Ethical Implication:* Infringes on individual privacy rights and can lead to surveillance societies or identity theft.\n",
      "6.  **Job Displacement and Economic Inequality:** As AI automates more tasks, there's a risk of significant job displacement across various sectors, potentially exacerbating economic inequality and social unrest if not managed properly.\n",
      "    *   *Ethical Implication:* Raises questions of distributive justice and societal well-being.\n",
      "7.  **Reinforcement of Power Structures:** Those who control and develop AI have significant power to shape societal norms and outcomes. This can further entrench existing power structures or create new ones, potentially leading to technological authoritarianism.\n",
      "    *   *Ethical Implication:* Threatens democratic principles and human flourishing.\n",
      "8.  **Ethical Dilemmas and Moral Agency:** In situations with no clear right or wrong answer (e.g., self-driving cars in unavoidable accident scenarios), AI must be programmed with explicit or implicit ethical frameworks, raising profound questions about who decides these moral rules and how.\n",
      "    *   *Ethical Implication:* Challenges fundamental human moral reasoning and societal values.\n",
      "\n",
      "## Proposed Framework for Accountability and Transparency\n",
      "\n",
      "To navigate these challenges, a multi-faceted framework is necessary, encompassing legal, technical, organizational, and societal dimensions.\n",
      "\n",
      "### Guiding Principles:\n",
      "\n",
      "1.  **Human-Centricity:** AI systems should augment human capabilities, respect human dignity, and ultimately serve human well-being. Human oversight and intervention should always be possible, especially in critical decisions.\n",
      "2.  **Fairness and Non-Discrimination:** AI systems must be designed, developed, and deployed to avoid unfair bias and discrimination, ensuring equitable treatment and opportunities for all.\n",
      "3.  **Transparency and Explainability:** The decision-making processes of AI systems should be as understandable and interpretable as possible, commensurate with the risk and impact of their decisions.\n",
      "4.  **Accountability and Redressability:** Clear lines of responsibility must be established for AI systems, and mechanisms must exist for affected individuals to seek explanation, challenge decisions, and obtain redress for harm.\n",
      "5.  **Robustness and Safety:** AI systems must be reliable, secure, and resilient to errors, manipulation, and cyber-attacks, ensuring they perform as intended and do not cause unintended harm.\n",
      "6.  **Privacy and Data Governance:** Strict data protection principles must be applied throughout the AI lifecycle, respecting individual privacy rights and ensuring responsible data collection, use, and storage.\n",
      "7.  **Beneficence and Sustainability:** AI development and deployment should contribute positively to society, aligning with ethical values and environmental sustainability goals.\n",
      "\n",
      "### Framework Pillars for Accountability and Transparency:\n",
      "\n",
      "**1. Legal and Regulatory Frameworks:**\n",
      "\n",
      "*   **Sector-Specific Regulations:** Develop laws tailored to high-risk AI applications (e.g., healthcare, finance, justice), mandating ethical guidelines, auditing requirements, and liability rules. (e.g., EU AI Act, which classifies AI by risk level).\n",
      "*   **\"Right to Explanation\" and Human Review:** Legally mandate that individuals affected by AI-driven decisions have the right to understand the basis of the decision and to request human review or intervention, especially in high-stakes contexts.\n",
      "*   **Clear Liability Regimes:** Establish legal frameworks that clearly assign accountability for harm caused by AI systems (e.g., producer liability, operator liability) to ensure victims can seek redress.\n",
      "*   **Data Protection Laws:** Strengthen and enforce comprehensive data protection regulations (like GDPR) that govern the collection, processing, and use of data for AI training and deployment.\n",
      "*   **Standardization and Certification:** Develop industry standards and potentially certification processes for AI systems to demonstrate compliance with ethical, safety, and performance requirements.\n",
      "\n",
      "**2. Technical and Methodological Solutions:**\n",
      "\n",
      "*   **Explainable AI (XAI) Tools:** Invest in and develop tools and techniques that make AI models more interpretable, allowing developers, auditors, and users to understand how a decision was reached. This includes techniques like LIME, SHAP, and causal inference.\n",
      "*   **Bias Detection and Mitigation Tools:** Implement tools to proactively identify and mitigate algorithmic biases in data collection, model training, and deployment, alongside continuous monitoring for discriminatory outcomes.\n",
      "*   **Robustness and Adversarial Testing:** Develop rigorous testing methodologies to ensure AI systems are resilient to adversarial attacks, data perturbations, and unexpected inputs, enhancing reliability and safety.\n",
      "*   **Data Provenance and Audit Trails:** Implement mechanisms to track the origin and transformations of data used to train AI models, creating comprehensive audit trails for transparency and debugging.\n",
      "*   **Privacy-Preserving AI:** Utilize techniques like federated learning, differential privacy, and homomorphic encryption to train AI models without directly accessing sensitive raw data.\n",
      "*   **Algorithmic Transparency Reports:** Encourage or mandate the publication of \"nutrition labels\" or impact assessments for AI systems, detailing their purpose, data sources, performance metrics, and known limitations/risks.\n",
      "\n",
      "**3. Organizational and Governance Mechanisms:**\n",
      "\n",
      "*   **AI Ethics Boards/Committees:** Establish independent or internal AI ethics boards composed of diverse experts (technologists, ethicists, legal scholars, social scientists) to review, guide, and oversee the development and deployment of AI.\n",
      "*   **AI Impact Assessments (AIIA):** Mandate comprehensive assessments before deploying high-risk AI systems, similar to environmental or privacy impact assessments, to identify and mitigate potential ethical, social, and economic risks.\n",
      "*   **Ethical AI Guidelines and Codes of Conduct:** Develop and enforce internal ethical guidelines and codes of conduct for AI developers, researchers, and deployers, integrating ethical considerations into the AI lifecycle from design to decommission.\n",
      "*   **Responsible AI Leadership and Training:** Foster a culture of responsible AI through leadership commitment, continuous ethical training for all involved personnel, and the allocation of resources for ethical AI research and implementation.\n",
      "*   **Post-Deployment Monitoring and Auditing:** Implement continuous monitoring systems to track AI performance, identify unintended consequences, and trigger human intervention when necessary. Regular independent audits should assess compliance with ethical and performance standards.\n",
      "*   **Whistleblower Protections:** Create safe channels and protections for individuals to report concerns about potentially harmful or unethical AI deployments.\n",
      "\n",
      "**4. Societal and Educational Initiatives:**\n",
      "\n",
      "*   **Public Education and Digital Literacy:** Promote widespread public understanding of AI's capabilities, limitations, and ethical implications, empowering citizens to engage critically with AI systems.\n",
      "*   **Multi-Stakeholder Dialogue:** Foster ongoing dialogue and collaboration among governments, industry, academia, civil society organizations, and the public to shape AI policy and best practices.\n",
      "*   **Ethical AI Research Funding:** Prioritize and fund research specifically focused on ethical AI, including explainability, bias mitigation, fairness metrics, and value alignment.\n",
      "*   **Citizen Participation:** Include citizen panels or participatory design approaches in the development and deployment of AI systems, especially those with significant public impact.\n",
      "\n",
      "By implementing this comprehensive framework, societies can harness the transformative power of AI while proactively addressing its ethical challenges, ensuring that AI development and deployment are accountable, transparent, and ultimately serve the greater good. This requires continuous adaptation, as AI technology evolves and its societal impacts become clearer.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are judging a competition between 2 competitors.\n",
      "Each model has been given this question:\n",
      "\n",
      "How would you evaluate the ethical implications of using artificial intelligence in decision-making processes, considering both potential benefits and risks, and what framework would you propose to ensure accountability and transparency?\n",
      "\n",
      "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
      "Respond with JSON, and only JSON, with the following format:\n",
      "{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}\n",
      "\n",
      "Here are the responses from each competitor:\n",
      "\n",
      "# Response from competitor 1\n",
      "\n",
      "Evaluating the ethical implications of using artificial intelligence (AI) in decision-making processes requires a balanced consideration of both its potential benefits and risks. Here’s a detailed analysis along with a proposed framework to ensure accountability and transparency.\n",
      "\n",
      "### Ethical Implications\n",
      "\n",
      "#### Potential Benefits:\n",
      "1. **Efficiency and Scalability**: AI can process vast amounts of data faster than humans, improving decision-making speed and efficiency in various domains such as healthcare, finance, and logistics.\n",
      "2. **Data-Driven Insights**: AI can uncover patterns and insights from data that might not be visible through traditional analytical methods, enhancing the quality of decisions.\n",
      "3. **Reduction of Human Bias**: If designed correctly, AI can help alleviate certain cognitive biases present in human decision-makers, promoting more objective outcomes.\n",
      "\n",
      "#### Potential Risks:\n",
      "1. **Bias and Discrimination**: AI systems can inadvertently perpetuate or amplify biases present in training data, leading to discriminatory outcomes in critical areas such as hiring, law enforcement, and credit scoring.\n",
      "2. **Lack of Accountability**: Decisions made by AI can be opaque, making it difficult to attribute responsibility when things go wrong. This can undermine trust in institutions that utilize AI.\n",
      "3. **Privacy Concerns**: The collection and analysis of personal data can lead to violations of privacy rights, especially if individuals are not informed or consent is not obtained.\n",
      "4. **Autonomy and Control**: Over-reliance on AI for decision-making can diminish human agency, as people may become passive recipients of decisions rather than active participants.\n",
      "\n",
      "### Framework for Accountability and Transparency\n",
      "\n",
      "To address the ethical implications of AI in decision-making, a structured framework is essential. This framework should include the following components:\n",
      "\n",
      "1. **Ethical Guidelines and Standards**:\n",
      "   - Establish baseline ethical principles (e.g., fairness, accountability, transparency, privacy, and human dignity) that guide AI development and deployment.\n",
      "   - Use established frameworks such as the IEEE's Ethically Aligned Design or the EU’s Ethics Guidelines for Trustworthy AI.\n",
      "\n",
      "2. **Transparency Mechanisms**:\n",
      "   - Promote explainable AI (XAI) techniques that enable users and stakeholders to understand AI decision-making processes and outcomes.\n",
      "   - Ensure public access to documentation regarding AI systems, including their design, data sources, and algorithms used.\n",
      "\n",
      "3. **Bias Audits and Fairness Measures**:\n",
      "   - Implement regular audits of AI systems to identify and mitigate biases, incorporating fairness metrics that assess the impact of AI decisions across different demographic groups.\n",
      "   - Engage diverse stakeholders in the development process to ensure that the perspectives and experiences of all affected groups are considered.\n",
      "\n",
      "4. **Accountability Structures**:\n",
      "   - Define clear lines of accountability for AI decisions, ensuring that human overseers are responsible for outcomes.\n",
      "   - Establish incident reporting mechanisms to track and address failures or biases in AI systems promptly.\n",
      "\n",
      "5. **Stakeholder Engagement and Public Discourse**:\n",
      "   - Involve stakeholders—including community representatives, ethicists, and technologists—in the design and evaluation of AI systems to address societal concerns collaboratively.\n",
      "   - Foster public discourse around AI use, its implications, and community values to ensure broader societal input in decision-making processes.\n",
      "\n",
      "6. **Regulatory Oversight**:\n",
      "   - Advocate for appropriate regulations that govern AI use in decision-making, which could include standards for data protection and algorithmic accountability.\n",
      "   - Encourage adaptability in regulations to keep pace with rapidly evolving technology.\n",
      "\n",
      "7. **Continuous Monitoring and Feedback**:\n",
      "   - Establish a system for ongoing monitoring of AI impacts, including stakeholder feedback mechanisms, to assess the effectiveness of implemented ethical guidelines.\n",
      "\n",
      "By adopting this framework, organizations can work towards ensuring that AI systems are used ethically, responsibly, and transparently while harnessing their benefits to enhance decision-making. Ultimately, maintaining a human-centric approach is vital to fostering trust and maximizing the positive impact of AI in society.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "The use of artificial intelligence in decision-making processes presents a complex ethical landscape, balancing immense potential for good with significant risks. Evaluating these implications requires a nuanced perspective, considering both the benefits AI can bring and the critical challenges it poses to human values, rights, and societal structures.\n",
      "\n",
      "## Ethical Implications: Benefits and Risks\n",
      "\n",
      "### Potential Benefits:\n",
      "\n",
      "1.  **Enhanced Efficiency and Speed:** AI can process vast amounts of data and make decisions far more quickly than humans, leading to faster service delivery, more responsive systems, and optimized operations in areas like logistics, finance, and emergency response.\n",
      "2.  **Improved Accuracy and Consistency:** For well-defined tasks, AI can reduce human error, fatigue, and emotional bias, leading to more consistent and often more accurate outcomes. This is particularly valuable in fields like medical diagnosis, quality control, and fraud detection.\n",
      "3.  **Identification of Hidden Patterns:** AI's ability to analyze complex datasets can uncover correlations and insights that humans might miss, leading to innovative solutions, better predictive models (e.g., disease outbreaks, market trends), and more informed strategic decisions.\n",
      "4.  **Scalability:** AI models can be deployed across a wide range of applications and scale up to meet demand without the limitations of human resources, enabling the delivery of services to a larger population.\n",
      "5.  **Reduced Human Bias (in theory):** While AI can amplify existing biases, it also offers the potential, if designed and trained carefully, to mitigate certain forms of human bias (e.g., favoritism, prejudice based on personal feelings) by applying objective criteria.\n",
      "6.  **Augmentation of Human Capabilities:** Rather than replacing humans, AI can serve as a powerful tool, augmenting human decision-makers with data-driven insights, allowing them to focus on more complex, creative, or empathetic aspects of a problem.\n",
      "\n",
      "### Potential Risks and Ethical Concerns:\n",
      "\n",
      "1.  **Algorithmic Bias and Discrimination:** AI systems learn from data, and if the data reflects historical or societal biases, the AI will learn and perpetuate these biases, leading to discriminatory outcomes. This is a critical concern in areas like criminal justice (sentencing, policing), hiring, loan applications, and healthcare.\n",
      "    *   *Ethical Implication:* Undermines fairness, equality, and justice; can exacerbate societal inequalities.\n",
      "2.  **Lack of Transparency and Explainability (\"Black Box\" Problem):** Many advanced AI models (especially deep learning) are \"black boxes,\" making it difficult or impossible for humans to understand how they arrive at a particular decision. This makes auditing, identifying errors, and challenging outcomes incredibly difficult.\n",
      "    *   *Ethical Implication:* Erodes trust, hinders accountability, violates the right to explanation, and challenges due process.\n",
      "3.  **Accountability Gap:** When an AI system makes a flawed or harmful decision, it's often unclear who is responsible: the developer, the deployer, the data provider, the user, or the AI itself? This \"liability vacuum\" can impede redress for harm.\n",
      "    *   *Ethical Implication:* Undermines justice and victim compensation; can lead to a diffusion of responsibility.\n",
      "4.  **Autonomy and Loss of Human Control/Oversight:** Over-reliance on AI can lead to a gradual ceding of human judgment and control, especially in critical domains like autonomous weapons systems or high-stakes financial trading. Humans may become complacent or unable to intervene effectively.\n",
      "    *   *Ethical Implication:* Risks dehumanization, loss of moral agency, and potentially catastrophic unintended consequences.\n",
      "5.  **Privacy Violations and Data Security:** AI systems often require vast amounts of personal data for training and operation, raising concerns about data collection, storage, use, and potential breaches.\n",
      "    *   *Ethical Implication:* Infringes on individual privacy rights and can lead to surveillance societies or identity theft.\n",
      "6.  **Job Displacement and Economic Inequality:** As AI automates more tasks, there's a risk of significant job displacement across various sectors, potentially exacerbating economic inequality and social unrest if not managed properly.\n",
      "    *   *Ethical Implication:* Raises questions of distributive justice and societal well-being.\n",
      "7.  **Reinforcement of Power Structures:** Those who control and develop AI have significant power to shape societal norms and outcomes. This can further entrench existing power structures or create new ones, potentially leading to technological authoritarianism.\n",
      "    *   *Ethical Implication:* Threatens democratic principles and human flourishing.\n",
      "8.  **Ethical Dilemmas and Moral Agency:** In situations with no clear right or wrong answer (e.g., self-driving cars in unavoidable accident scenarios), AI must be programmed with explicit or implicit ethical frameworks, raising profound questions about who decides these moral rules and how.\n",
      "    *   *Ethical Implication:* Challenges fundamental human moral reasoning and societal values.\n",
      "\n",
      "## Proposed Framework for Accountability and Transparency\n",
      "\n",
      "To navigate these challenges, a multi-faceted framework is necessary, encompassing legal, technical, organizational, and societal dimensions.\n",
      "\n",
      "### Guiding Principles:\n",
      "\n",
      "1.  **Human-Centricity:** AI systems should augment human capabilities, respect human dignity, and ultimately serve human well-being. Human oversight and intervention should always be possible, especially in critical decisions.\n",
      "2.  **Fairness and Non-Discrimination:** AI systems must be designed, developed, and deployed to avoid unfair bias and discrimination, ensuring equitable treatment and opportunities for all.\n",
      "3.  **Transparency and Explainability:** The decision-making processes of AI systems should be as understandable and interpretable as possible, commensurate with the risk and impact of their decisions.\n",
      "4.  **Accountability and Redressability:** Clear lines of responsibility must be established for AI systems, and mechanisms must exist for affected individuals to seek explanation, challenge decisions, and obtain redress for harm.\n",
      "5.  **Robustness and Safety:** AI systems must be reliable, secure, and resilient to errors, manipulation, and cyber-attacks, ensuring they perform as intended and do not cause unintended harm.\n",
      "6.  **Privacy and Data Governance:** Strict data protection principles must be applied throughout the AI lifecycle, respecting individual privacy rights and ensuring responsible data collection, use, and storage.\n",
      "7.  **Beneficence and Sustainability:** AI development and deployment should contribute positively to society, aligning with ethical values and environmental sustainability goals.\n",
      "\n",
      "### Framework Pillars for Accountability and Transparency:\n",
      "\n",
      "**1. Legal and Regulatory Frameworks:**\n",
      "\n",
      "*   **Sector-Specific Regulations:** Develop laws tailored to high-risk AI applications (e.g., healthcare, finance, justice), mandating ethical guidelines, auditing requirements, and liability rules. (e.g., EU AI Act, which classifies AI by risk level).\n",
      "*   **\"Right to Explanation\" and Human Review:** Legally mandate that individuals affected by AI-driven decisions have the right to understand the basis of the decision and to request human review or intervention, especially in high-stakes contexts.\n",
      "*   **Clear Liability Regimes:** Establish legal frameworks that clearly assign accountability for harm caused by AI systems (e.g., producer liability, operator liability) to ensure victims can seek redress.\n",
      "*   **Data Protection Laws:** Strengthen and enforce comprehensive data protection regulations (like GDPR) that govern the collection, processing, and use of data for AI training and deployment.\n",
      "*   **Standardization and Certification:** Develop industry standards and potentially certification processes for AI systems to demonstrate compliance with ethical, safety, and performance requirements.\n",
      "\n",
      "**2. Technical and Methodological Solutions:**\n",
      "\n",
      "*   **Explainable AI (XAI) Tools:** Invest in and develop tools and techniques that make AI models more interpretable, allowing developers, auditors, and users to understand how a decision was reached. This includes techniques like LIME, SHAP, and causal inference.\n",
      "*   **Bias Detection and Mitigation Tools:** Implement tools to proactively identify and mitigate algorithmic biases in data collection, model training, and deployment, alongside continuous monitoring for discriminatory outcomes.\n",
      "*   **Robustness and Adversarial Testing:** Develop rigorous testing methodologies to ensure AI systems are resilient to adversarial attacks, data perturbations, and unexpected inputs, enhancing reliability and safety.\n",
      "*   **Data Provenance and Audit Trails:** Implement mechanisms to track the origin and transformations of data used to train AI models, creating comprehensive audit trails for transparency and debugging.\n",
      "*   **Privacy-Preserving AI:** Utilize techniques like federated learning, differential privacy, and homomorphic encryption to train AI models without directly accessing sensitive raw data.\n",
      "*   **Algorithmic Transparency Reports:** Encourage or mandate the publication of \"nutrition labels\" or impact assessments for AI systems, detailing their purpose, data sources, performance metrics, and known limitations/risks.\n",
      "\n",
      "**3. Organizational and Governance Mechanisms:**\n",
      "\n",
      "*   **AI Ethics Boards/Committees:** Establish independent or internal AI ethics boards composed of diverse experts (technologists, ethicists, legal scholars, social scientists) to review, guide, and oversee the development and deployment of AI.\n",
      "*   **AI Impact Assessments (AIIA):** Mandate comprehensive assessments before deploying high-risk AI systems, similar to environmental or privacy impact assessments, to identify and mitigate potential ethical, social, and economic risks.\n",
      "*   **Ethical AI Guidelines and Codes of Conduct:** Develop and enforce internal ethical guidelines and codes of conduct for AI developers, researchers, and deployers, integrating ethical considerations into the AI lifecycle from design to decommission.\n",
      "*   **Responsible AI Leadership and Training:** Foster a culture of responsible AI through leadership commitment, continuous ethical training for all involved personnel, and the allocation of resources for ethical AI research and implementation.\n",
      "*   **Post-Deployment Monitoring and Auditing:** Implement continuous monitoring systems to track AI performance, identify unintended consequences, and trigger human intervention when necessary. Regular independent audits should assess compliance with ethical and performance standards.\n",
      "*   **Whistleblower Protections:** Create safe channels and protections for individuals to report concerns about potentially harmful or unethical AI deployments.\n",
      "\n",
      "**4. Societal and Educational Initiatives:**\n",
      "\n",
      "*   **Public Education and Digital Literacy:** Promote widespread public understanding of AI's capabilities, limitations, and ethical implications, empowering citizens to engage critically with AI systems.\n",
      "*   **Multi-Stakeholder Dialogue:** Foster ongoing dialogue and collaboration among governments, industry, academia, civil society organizations, and the public to shape AI policy and best practices.\n",
      "*   **Ethical AI Research Funding:** Prioritize and fund research specifically focused on ethical AI, including explainability, bias mitigation, fairness metrics, and value alignment.\n",
      "*   **Citizen Participation:** Include citizen panels or participatory design approaches in the development and deployment of AI systems, especially those with significant public impact.\n",
      "\n",
      "By implementing this comprehensive framework, societies can harness the transformative power of AI while proactively addressing its ethical challenges, ensuring that AI development and deployment are accountable, transparent, and ultimately serve the greater good. This requires continuous adaptation, as AI technology evolves and its societal impacts become clearer.\n",
      "\n",
      "\n",
      "\n",
      "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\n"
     ]
    }
   ],
   "source": [
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_messages = [{\"role\": \"user\", \"content\": judge}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"results\": [\"2\", \"1\"]}\n"
     ]
    }
   ],
   "source": [
    "# Judgement time!\n",
    "\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"o4-mini\",\n",
    "    messages=judge_messages,\n",
    ")\n",
    "results = response.choices[0].message.content\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: gemini-2.5-flash\n",
      "Rank 2: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# OK let's turn this into results!\n",
    "\n",
    "results_dict = json.loads(results)\n",
    "ranks = results_dict[\"results\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result)-1]\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Which pattern(s) did this use? Try updating this to add another Agentic design pattern.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">These kinds of patterns - to send a task to multiple models, and evaluate results,\n",
    "            are common where you need to improve the quality of your LLM response. This approach can be universally applied\n",
    "            to business projects where accuracy is critical.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
